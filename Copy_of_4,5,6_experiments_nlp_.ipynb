{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUGd4azN_sfC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello! This is a simple example, and it works without libraries.\"\n",
        "stop_words = [\"is\", \"a\", \"and\", \"it\", \"the\", \"this\", \"to\", \"of\"]\n",
        "punctuation_marks = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "clean_text = \"\"\n",
        "for char in text:\n",
        "  if char not in punctuation_marks:\n",
        "    clean_text += char\n",
        "tokens = clean_text.split()\n",
        "filtered_tokens = []\n",
        "for word in tokens:\n",
        "  if word.lower() not in stop_words:\n",
        "    filtered_tokens.append(word)\n",
        "print(f\"Original Text: {text}\")\n",
        "print(f\"Tokens: {tokens}\")\n",
        "print(f\"StopWords: {filtered_tokens}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vpC2Tdsq5YI",
        "outputId": "88a7b40f-5b79-4e5d-d4ef-cc570638b247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: Hello! This is a simple example, and it works without libraries.\n",
            "Tokens: ['Hello', 'This', 'is', 'a', 'simple', 'example', 'and', 'it', 'works', 'without', 'libraries']\n",
            "StopWords: ['Hello', 'simple', 'example', 'works', 'without', 'libraries']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:3: SyntaxWarning: invalid escape sequence '\\,'\n",
            "<>:3: SyntaxWarning: invalid escape sequence '\\,'\n",
            "/tmp/ipython-input-3801250740.py:3: SyntaxWarning: invalid escape sequence '\\,'\n",
            "  punctuation_marks = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.wsd import lesk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbt6168C_8BR",
        "outputId": "58e29147-ed33-43e4-bbd5-8ca1798d9be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=\"balayya is not a name, it is an emotion. Jai balayya\"\n",
        "words=word_tokenize (sentence)\n",
        "word='emotion'\n",
        "sense=lesk (words, word)\n",
        "if sense:\n",
        "  print (f\"best sense for '(word)': {sense.name()}\")\n",
        "  print(f\"definition: {sense.definition()}\")\n",
        "else:\n",
        "  print(f\"no sense found for '{word}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2fdsGquABJ_",
        "outputId": "0929ad01-a72c-4569-d0ac-047319c2c3a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best sense for '(word)': emotion.n.01\n",
            "definition: any strong feeling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "words = [\"program\", \"programs\", \"programmer\", \"programming\", \"programmed\"]\n",
        "\n",
        "print(\"Converting Word to its Stem\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "for w in words:\n",
        "    print(f\"{w} --> {ps.stem(w)}\")\n",
        "\n",
        "sentence = \"The programmers are programming a new program in Python\"\n",
        "\n",
        "tokenized_words = nltk.word_tokenize(sentence)\n",
        "\n",
        "print(\"\\nSentence Stemming:\")\n",
        "\n",
        "stemmed_sentence = [ps.stem(w) for w in tokenized_words]\n",
        "\n",
        "print(\" \".join(stemmed_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrF256rdAFp_",
        "outputId": "5c18108b-b49f-4846-9922-088a8fdb4984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting Word to its Stem\n",
            "------------------------------\n",
            "program --> program\n",
            "programs --> program\n",
            "programmer --> programm\n",
            "programming --> program\n",
            "programmed --> program\n",
            "\n",
            "Sentence Stemming:\n",
            "the programm are program a new program in python\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_dict = {\n",
        "    \"cat\": \"NOUN\",\n",
        "    \"dog\": \"NOUN\",\n",
        "    \"child\": \"NOUN\",\n",
        "    \"run\": \"VERB\",\n",
        "    \"eat\": \"VERB\",\n",
        "    \"play\": \"VERB\",\n",
        "    \"happy\": \"ADJECTIVE\",\n",
        "    \"blue\": \"ADJECTIVE\",\n",
        "    \"i\": \"PRONOUN\",\n",
        "    \"you\": \"PRONOUN\"\n",
        "}\n",
        "\n",
        "word = input().lower()\n",
        "\n",
        "if word in pos_dict:\n",
        "    print(pos_dict[word])\n",
        "else:\n",
        "    print(\"UNKNOWN\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twL9PdgdAJkI",
        "outputId": "01a37eeb-c33e-441b-e977-8f09bb406895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run\n",
            "VERB\n"
          ]
        }
      ]
    }
  ]
}